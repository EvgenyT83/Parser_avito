# Парсер
Первый проект в списке – парсер сайтов. Это программа, которая просматривает код веб-сайта и получает оттуда какую-то информацию. 

Предположим, есть сайт «Авито». Мы можем сделать программу, которая будет «как бы заходить» на Авито; просматривать объявления (через программный код на страницах); и записывать в текстовый файл информацию из этих объявлений.

Пусть скрипт пишет в файл ссылку на объявление, контактный телефон, цену и описание. Затем этот файл сортируется по цене аренды. Такая программа и будет являться парсером или, как их часто называют, веб-скрапером.

В тренировочно-образовательных целях необходимо всё сделать максимально вручную, но без фанатизма. Поэтому используем модуль requests для работы с сетевыми запросами (для получения кода сайта, регистрации, авторизации). Библиотека BeautifulSoup понадобится для разбора и выдергивания информации из HTML-кода сайта, который мы получили с помощью requests.

Разработка парсера заставит разобраться с тем, что такое, зачем нужны и как работают сетевые протоколы HTTP/HTTPS. Придётся выяснить, что такое HTTP-запрос – из чего он состоит; как работать с GET, POST, PUT, DELETE-запросами; чем они отличаются; как формировать заголовки запросов. Предстоит покопаться со статус-кодами, URL-адресами, схемами авторизации, сессиями, редиректами, прокси и куки-файлами. Параллельно познакомиться с форматом JSON и вникнуть в HTML/CSS-код, семантику и DOM-модель веб-страницы.

Работа с сетевыми протоколами – это фундаментальные computer science навыки, без которых называть себя полноценным программистом немного не справедливо.
